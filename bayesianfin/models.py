# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_garch_like_modelling.ipynb.

# %% auto 0
__all__ = ['DFFeature', 'Variance', 'LogReturn', 'FeatureEngineer', 'garch_like_model']

# %% ../nbs/01_garch_like_modelling.ipynb 4
from dataclasses import dataclass
from datetime import timedelta
from itertools import product
import abc
import arviz as az
import jax.numpy as jnp
import matplotlib.pyplot as plt
import numpy as np
import numpy.typing as npt
import numpyro
import numpyro.distributions as dist
import polars as pl
import seaborn as sns
from jax import random
from numpyro.infer import MCMC, NUTS, Predictive
from tqdm import tqdm

# %% ../nbs/01_garch_like_modelling.ipynb 5
az.style.use("arviz-darkgrid")

# %% ../nbs/01_garch_like_modelling.ipynb 9
@dataclass
class DFFeature(abc.ABC):
    source_field: str
    feature_name: str

    @abc.abstractmethod
    def extract(self, df: pl.DataFrame) -> pl.DataFrame:
        pass


class Variance(DFFeature):
    rolling_variance_window: int = 3

    def extract(self, df: pl.DataFrame) -> pl.DataFrame:
        return df.with_columns(
            pl.col(self.source_field)
            .rolling_var(self.rolling_variance_window)
            .alias(self.feature_name)
        )


class LogReturn(DFFeature):
    def extract(self, df: pl.DataFrame) -> pl.DataFrame:
        return df.with_columns(pl.col(self.source_field).log().alias(self.feature_name))


class FeatureEngineer:
    """A class for creating lagged features from time series data.

    This class handles the creation of lagged (shifted) features that can be used for
    GARCH-like models and other time series forecasting tasks.

    Attributes:
        columns: List of column names to create lags for
        n_shifts: Number of lag periods to create
        drop_nulls: whether to drop the nulls after rolling window calculations
    """

    def __init__(
        self,
        transforms: list[DFFeature],
        columns=["ret", "var"],
        n_shifts=3,
        drop_nulls: bool = True,
        rolling_variance_window: int = 3,
    ):
        """Initialize the FeatureEngineer.

        Args:
            columns: List of column names to create lags for (default: ['ret', 'var'])
            n_shifts: Number of lag periods to create (default: 3)
            drop_nulls: whether to drop the nulls after rolling window calculations
        """
        self.transforms = transforms
        self.columns = columns if isinstance(columns, list) else [columns]
        self.n_shifts = n_shifts
        self.drop_nulls = drop_nulls
        self.rolling_variance_window = rolling_variance_window

    def create_features(self, df: pl.DataFrame) -> pl.DataFrame:
        """Create lagged features from the input DataFrame.

        Args:
            df: Input DataFrame containing time series data

        Returns:
            DataFrame with original columns plus lagged features
        """
        # Create a copy of the dataframe to avoid modifying the original
        for t in self.transforms:
            df = t.extract(df)

        result_df = df.clone()

        # Create lagged features for each specified column
        for col in self.columns:
            # Check if column exists in dataframe
            if col not in df.columns:
                print(f"Warning: Column '{col}' not found in dataframe. Skipping.")
                continue

            # Create each lag
            for shift in range(1, self.n_shifts + 1):
                # Create new column name (e.g., prev_ret_1, prev_var_2)
                new_col_name = f"prev_{col}_{shift}"

                # Add the shifted column to the dataframe
                result_df = result_df.with_columns(
                    pl.col(col).shift(shift).alias(new_col_name)
                )
        if self.drop_nulls:
            result_df = result_df.drop_nulls()
        return result_df

    def to_numpy_dict(self, df: pl.DataFrame) -> dict:
        """Convert the dataframe with lagged features to a dictionary of NumPy arrays.

        This method extracts the original columns that were used to create lags,
        as well as all the generated lag columns, and converts them to NumPy arrays.
        The resulting dictionary can be used directly with NumPyro models.

        Args:
            df: DataFrame with lagged features created by create_features()

        Returns:
            Dictionary mapping column names to NumPy arrays
        """
        # Create a new dataframe with the features we want to process
        features_df = df.clone()

        # Dictionary to store the NumPy arrays
        numpy_dict = {}

        # Add original columns
        for col in self.columns:
            if col in features_df.columns:
                numpy_dict[col] = features_df[col].to_numpy()

        # Add lagged features
        for col in self.columns:
            for shift in range(1, self.n_shifts + 1):
                lag_col = f"prev_{col}_{shift}"
                if lag_col in features_df.columns:
                    numpy_dict[lag_col] = features_df[lag_col].to_numpy()

        return numpy_dict

    def get_iterator(self, site: str | None = None):
        if site is None:
            site = self.columns
        else:
            site = [site]
        for pair in product(site, range(1, self.n_shifts + 1)):
            yield pair

    def get_shift_pattern(self, site: str, shift: int, prefix: str = ""):
        return f"{prefix}prev_{site}_{shift}"

# %% ../nbs/01_garch_like_modelling.ipynb 17
def garch_like_model(
    present_value: npt.NDArray, past_values: dict[str, npt.NDArray]
) -> None:
    b = numpyro.sample("b", dist.Normal(0, 0.2))
    b_var = numpyro.sample("b_var", dist.Exponential(10))  # So it is positive

    coeffs = {}
    for col, s in feature_engineer.get_iterator("log_ret"):
        param_name = feature_engineer.get_shift_pattern(col, s)
        coeffs[param_name] = numpyro.sample(
            f"param_{param_name}", dist.Normal(0.0, 0.5)
        )

    for col, s in feature_engineer.get_iterator("var"):
        param_name = feature_engineer.get_shift_pattern(col, s)
        coeffs[param_name] = numpyro.sample(f"param_{param_name}", dist.Exponential(10))

    # Handle prediction case
    len_observations = len(present_value) if present_value is not None else 1

    with numpyro.plate("data", len_observations):
        mu = b
        for col, s in feature_engineer.get_iterator("log_ret"):
            param_name = feature_engineer.get_shift_pattern(col, s)
            mu += coeffs[param_name] * past_values[param_name]

        mu_var = b_var
        for col, s in feature_engineer.get_iterator("var"):
            param_name = feature_engineer.get_shift_pattern(col, s)
            mu_var += coeffs[param_name] * past_values[param_name]
        # Condition on observed values if provided
        numpyro.sample("log_ret", dist.Normal(mu, jnp.sqrt(mu_var)), obs=present_value)
